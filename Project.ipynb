{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Importing and cleaning the a sample of the FakeNewsCorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be importing the data with pandas cvs method. Cleaning the data will be done through a combination of the clean-text module and manual data cleaning, using regular expressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "\n",
    "def clean_text(text: str):\n",
    "    \"\"\"cleans raw data using re.sub() to remove double newlines, space, and tabs. Also replace dates, emails, urls, and numbers\"\"\"\n",
    "    text = text.lower()\n",
    "    \n",
    "    num_pattern = re.compile(r\"(\\d+)\")\n",
    "    date_pattern = re.compile(r\"((\\d{2})-(\\d{2})-(\\d{4}))\") #usind the dd-mm-yyyy format\n",
    "    email_pattern = re.compile(r\"(([\\w\\-_.]*)(@\\w+)(.com))\")\n",
    "    url_pattern = re.compile(r\"((https:\\/\\/www\\.)([a-zA-Z0-9]*)(\\.com))\")\n",
    "    \n",
    "    text = re.sub(\" +\", \" \", text)\n",
    "    text = re.sub(\"\\t+\", \"\\t\", text)\n",
    "    text = re.sub(\"\\n+\", \"\\n\", text)\n",
    "    text = re.sub(date_pattern, \"<DATE>\", text)\n",
    "    text = re.sub(email_pattern, \"<EMAIL>\", text)\n",
    "    text = re.sub(url_pattern, \"<URL>\", text)\n",
    "    text = re.sub(num_pattern, \"<NUM>\", text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def word_analasis_text(text: list):\n",
    "    \"\"\"returns reduction rate of vocabulary of tokenzied data before and after removing stopwords and stemming\"\"\"\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the data and run our functions. (Remember to run the functions first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the CVS file as raw text\n",
    "raw_data_fake_news = requests.get(\"https://raw.githubusercontent.com/several27/FakeNewsCorpus/master/news_sample.csv\").text\n",
    "\n",
    "#cleaning raw text\n",
    "cleaned_data_fake_news = clean_text(raw_data_fake_news)\n",
    "\n",
    "#tokenizing raw text\n",
    "tokenized_data_fake_news = nltk.word_tokenize(cleaned_data_fake_news)\n",
    "\n",
    "#doing a word analasis\n",
    "word_analasis = word_analasis_text(tokenized_data_fake_news)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
