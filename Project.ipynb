{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1: Importing and cleaning the a sample of the FakeNewsCorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be importing the data with pandas cvs method. Cleaning the data will be done through a combination of the clean-text module and manual data cleaning, using regular expressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "\n",
    "def clean_text(text: str):\n",
    "    \"\"\"cleans raw data using re.sub() to remove double newlines, space, and tabs. Also replace dates, emails, urls, and numbers\"\"\"\n",
    "    text = text.lower()\n",
    "    \n",
    "    num_pattern = re.compile(r\"(\\d+)\")\n",
    "    date_pattern = re.compile(r\"((\\d{2})-(\\d{2})-(\\d{4}))\") #usind the dd-mm-yyyy format\n",
    "    email_pattern = re.compile(r\"(([\\w\\-_.]*)(@\\w+)(.com))\")\n",
    "    url_pattern = re.compile(r\"((https:\\/\\/www\\.)([a-zA-Z0-9]*)(\\.com))\")\n",
    "    \n",
    "    text = re.sub(\" +\", \" \", text)\n",
    "    text = re.sub(\"\\t+\", \"\\t\", text)\n",
    "    text = re.sub(\"\\n+\", \"\\n\", text)\n",
    "    text = re.sub(date_pattern, \"<DATE>\", text)\n",
    "    text = re.sub(email_pattern, \"<EMAIL>\", text)\n",
    "    text = re.sub(url_pattern, \"<URL>\", text)\n",
    "    text = re.sub(num_pattern, \"<NUM>\", text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def word_analasis_text(text: list):\n",
    "    \"\"\"returns reduction rate of vocabulary of tokenzied data before and after removing stopwords and stemming\"\"\"\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the data and run our functions. (Remember to run the functions first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the CVS file as raw text\n",
    "raw_data_fake_news = requests.get(\"https://raw.githubusercontent.com/several27/FakeNewsCorpus/master/news_sample.csv\").text\n",
    "\n",
    "#cleaning raw text\n",
    "cleaned_data_fake_news = clean_text(raw_data_fake_news)\n",
    "\n",
    "#tokenizing raw text\n",
    "tokenized_data_fake_news = nltk.word_tokenize(cleaned_data_fake_news)\n",
    "\n",
    "#doing a word analasis\n",
    "word_analasis = word_analasis_text(tokenized_data_fake_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Simple Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Advanced Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Conclusions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
