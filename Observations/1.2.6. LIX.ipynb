{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "df = pd.read_csv(\"995K_subset.csv\", dtype={0: str, 1: str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Unnamed: 0  \\\n",
      "16569                     Scientists decided to officiall   \n",
      "127415   so succinctly: “Globalization: Where leaders ...   \n",
      "357921   #ShellNo! Shell gets final OK for #Arctic oil...   \n",
      "419231     the United Nations Security Council to address   \n",
      "502587  The ruling is unique and can pave the way for ...   \n",
      "549518  The map is part of an Earthjustice report Comi...   \n",
      "594003                           Solar goes up on a ro...   \n",
      "621617          to enter Mosul. U.S. Army Specialist Chas   \n",
      "668156                           Iraqi republic in 1958 w   \n",
      "711719                                                578   \n",
      "814411   a lack of transparency concerning the upcomin...   \n",
      "935403                        Presidents.” As the Clinton   \n",
      "\n",
      "                                                       id             domain  \\\n",
      "16569                                                 NaN                NaN   \n",
      "127415                                                NaN                NaN   \n",
      "357921  COP23, pipeline, Pope Francis, Ryan Zinke, Par...                NaN   \n",
      "419231                                                NaN                NaN   \n",
      "502587   stranded, air pollution, whales, Paris agreement                NaN   \n",
      "549518  rainforests, coal, forests, nuclear, wind powe...                NaN   \n",
      "594003  ocean, coral reefs, offshore oil and gas drill...                NaN   \n",
      "621617                                                NaN                NaN   \n",
      "668156                                                NaN                NaN   \n",
      "711719                                            8268234  feeds.reuters.com   \n",
      "814411                                                NaN                NaN   \n",
      "935403                                                NaN                NaN   \n",
      "\n",
      "            type                                                url content  \\\n",
      "16569        NaN                                                NaN           \n",
      "127415       NaN                                                NaN           \n",
      "357921       NaN                                                NaN           \n",
      "419231       NaN                                                NaN           \n",
      "502587       NaN                                                NaN           \n",
      "549518       NaN                                                NaN           \n",
      "594003       NaN                                                NaN           \n",
      "621617       NaN                                                NaN           \n",
      "668156       NaN                                                NaN           \n",
      "711719  reliable  http://feeds.reuters.com/reuters/UShealthcareNews           \n",
      "814411       NaN                                                NaN           \n",
      "935403       NaN                                                NaN           \n",
      "\n",
      "       scraped_at inserted_at updated_at title authors  keywords  \\\n",
      "16569         NaN         NaN        NaN   NaN     NaN       NaN   \n",
      "127415        NaN         NaN        NaN   NaN     NaN       NaN   \n",
      "357921        NaN         NaN        NaN   NaN     NaN       NaN   \n",
      "419231        NaN         NaN        NaN   NaN     NaN       NaN   \n",
      "502587        NaN         NaN        NaN   NaN     NaN       NaN   \n",
      "549518        NaN         NaN        NaN   NaN     NaN       NaN   \n",
      "594003        NaN         NaN        NaN   NaN     NaN       NaN   \n",
      "621617        NaN         NaN        NaN   NaN     NaN       NaN   \n",
      "668156        NaN         NaN        NaN   NaN     NaN       NaN   \n",
      "711719        NaN         NaN        NaN   NaN     NaN       NaN   \n",
      "814411        NaN         NaN        NaN   NaN     NaN       NaN   \n",
      "935403        NaN         NaN        NaN   NaN     NaN       NaN   \n",
      "\n",
      "       meta_keywords meta_description tags  summary source  lix  \n",
      "16569            NaN              NaN  NaN      NaN    NaN  NaN  \n",
      "127415           NaN              NaN  NaN      NaN    NaN  NaN  \n",
      "357921           NaN              NaN  NaN      NaN    NaN  NaN  \n",
      "419231           NaN              NaN  NaN      NaN    NaN  NaN  \n",
      "502587           NaN              NaN  NaN      NaN    NaN  NaN  \n",
      "549518           NaN              NaN  NaN      NaN    NaN  NaN  \n",
      "594003           NaN              NaN  NaN      NaN    NaN  NaN  \n",
      "621617           NaN              NaN  NaN      NaN    NaN  NaN  \n",
      "668156           NaN              NaN  NaN      NaN    NaN  NaN  \n",
      "711719           NaN              NaN  NaN      NaN    NaN  NaN  \n",
      "814411           NaN              NaN  NaN      NaN    NaN  NaN  \n",
      "935403           NaN              NaN  NaN      NaN    NaN  NaN  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check for missing values in the 'content' column\n",
    "missing_values = df['content'].isnull()\n",
    "\n",
    "# Fill missing values with an empty string\n",
    "df['content'].fillna('', inplace=True)\n",
    "\n",
    "# Apply the LIX computation function only to non-null values\n",
    "df['lix'] = df.loc[~missing_values, 'content'].apply(compute_lix)\n",
    "\n",
    "print(df[missing_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the LIX number for a given text\n",
    "def compute_lix(text):\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Tokenize each sentence into words\n",
    "    words = [word_tokenize(sentence) for sentence in sentences]\n",
    "    \n",
    "    # Flatten the list of words\n",
    "    words = [word for sublist in words for word in sublist]\n",
    "    \n",
    "    # Count the total number of words\n",
    "    W = len(words)\n",
    "    \n",
    "    # Count the number of long words (words with more than 6 letters)\n",
    "    L = sum(1 for word in words if len(word) > 6)\n",
    "    \n",
    "    # Count the number of sentences\n",
    "    S = len(sentences)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if W == 0:\n",
    "        return 0\n",
    "    \n",
    "    if S == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Compute the LIX number\n",
    "    lix = (W/S) + (L*100/W)\n",
    "    \n",
    "    return lix\n",
    "\n",
    "# Apply the LIX computation function to each article\n",
    "df['lix'] = df['content'].apply(compute_lix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain\n",
      "derfmagazine.com                    503.137530\n",
      "conservativeoutfitters.com          405.425923\n",
      "thepeoplescube.com                  137.517598\n",
      "worlddaily.info                     136.818267\n",
      "counterinformation.wordpress.com     96.605783\n",
      "Name: lix, dtype: float64\n",
      "domain\n",
      "thecivilian.co.nz      26.288702\n",
      "speld.nl               24.497733\n",
      "prepperwebsite.com     20.414966\n",
      "usapoliticszone.com    19.392904\n",
      "madpatriots.com        16.000000\n",
      "Name: lix, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Group the DataFrame by 'domain' and calculate the average LIX number for each domain\n",
    "avg_lix_by_domain = df.groupby('domain')['lix'].mean()\n",
    "\n",
    "print(avg_lix_by_domain.sort_values(ascending=False).head(5))\n",
    "print(avg_lix_by_domain.sort_values(ascending=False).tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "fake        49.044455\n",
      "reliable    48.241526\n",
      "Name: lix, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "label_to_category = {\n",
    "    \"fake\": \"fake\",\n",
    "    \"satire\": \"fake\",\n",
    "    \"bias\": \"fake\",\n",
    "    \"conspiracy\": \"fake\",\n",
    "    \"junksci\": \"fake\",\n",
    "    \"reliable\": \"reliable\",\n",
    "    \"political\": \"reliable\",\n",
    "    \"clickbait\": \"reliable\",\n",
    "}\n",
    "\n",
    "# Map the 'type' column to the corresponding category using label_to_category\n",
    "df['category'] = df['type'].map(label_to_category)\n",
    "\n",
    "# Group by category and compute the average LIX number for each group\n",
    "avg_lix_by_category = df.groupby('category')['lix'].mean()\n",
    "\n",
    "print(avg_lix_by_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "2018-02-10 13:43:39.521661    53.444444\n",
      "bias                          51.539691\n",
      "clickbait                     46.749425\n",
      "conspiracy                    49.799459\n",
      "fake                          45.494249\n",
      "hate                          49.173438\n",
      "junksci                       50.532957\n",
      "political                     49.999336\n",
      "reliable                      46.864244\n",
      "rumor                         48.223162\n",
      "satire                        44.906153\n",
      "unknown                       53.073473\n",
      "unreliable                    54.031617\n",
      "Name: lix, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Group the DataFrame by 'type' and calculate the average LIX number for each type\n",
    "avg_lix_by_type = df.groupby('type')['lix'].mean()\n",
    "\n",
    "# Print the average LIX number for each type\n",
    "print(avg_lix_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient: -0.01971114127586384\n",
      "P-value: 7.630665863342619e-70\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Drop rows with NaN values\n",
    "df.dropna(subset=['lix', 'category'], inplace=True)\n",
    "\n",
    "# Encode categorical variable (if necessary)\n",
    "# Example of label encoding\n",
    "df['category'] = df['category'].map({'fake': 0, 'reliable': 1})\n",
    "\n",
    "# Compute correlation between LIX numbers and categorization variable\n",
    "correlation = df['lix'].corr(df['category'])\n",
    "\n",
    "# Compute p-value for correlation coefficient\n",
    "_, p_value = pearsonr(df['lix'], df['category'])\n",
    "\n",
    "print(\"Correlation coefficient:\", correlation)\n",
    "print(\"P-value:\", p_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
